{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Trajectory Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import bins_y_s, add_user_categories_to_bin, mean_confidence_interval, normalize_user_bins, \\\n",
    "                    find_users_constraint, find_users_other_bin, estimate_for_users\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = '/dlabdata1/manosphere-rad/'\n",
    "df_sources = pd.read_csv(SRC + \"sources_final_trimmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_control(i):\n",
    "    cat = i[\"category\"]\n",
    "    if cat in cats_to_control:\n",
    "        i[\"category\"] = \"Control\"\n",
    "    return i\n",
    "\n",
    "cats_to_control = [\"center\", \"left-center\", \"right-center\", \"left\", \"right\"]\n",
    "cats_all = cats_to_control + [\"PUA\", \"Alt-right\", \"MGTOW\", \"MRA\", \"Incel\"]\n",
    "cats = [cat for cat in cats_all if cat not in cats_to_control]\n",
    "cats.append(\"Control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or use already computed checkpoint?\n",
    "CREATE_BIN_USERS = True\n",
    "\n",
    "if CREATE_BIN_USERS:\n",
    "    # Read authors\n",
    "    with gzip.open(SRC+\"users_youtube.json.gz\", 'rb') as f:\n",
    "        authors_dict = json.load(f)\n",
    "\n",
    "    # Create bins\n",
    "    bin_users = {b:dict() for b in bins_y_s}\n",
    "\n",
    "    min_num_users = 1\n",
    "    print(len(authors_dict))\n",
    "    for idx, (key, item) in  tqdm(enumerate(authors_dict.items())):\n",
    "        relevant_items = [to_control(i) for i in item if i[\"category\"] in cats_all\n",
    "                                              and i[\"channel_id\"] in df_sources.Id.values]\n",
    "\n",
    "        if len(relevant_items) < min_num_users:\n",
    "            continue\n",
    "        for comment in relevant_items:\n",
    "            add_user_categories_to_bin(bin_users, key, comment[\"category\"], comment[\"timestamp\"])\n",
    "\n",
    "    normalize_user_bins(bin_users)\n",
    "\n",
    "    # Checkpoint\n",
    "    with open(\"../data/bin_users.pickle\", \"wb\") as f:\n",
    "        pickle.dump(bin_users, f)\n",
    "elif CREATE_DF:\n",
    "    with open(\"../data/bin_users.pickle\", \"rb\") as f:\n",
    "        bin_users = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_names = [\n",
    "        \"MGTOW\", \n",
    "        \"MRA\",  \n",
    "        \"Incel\", \n",
    "        \"PUA\",\n",
    "        \"Manosphere\",\n",
    "        \"Control\",\n",
    "        \"Alt-lite or I.D.W.\", \n",
    "        \"Alt-lite\",\n",
    "        \"I.D.W.\",\n",
    "    ]\n",
    "\n",
    "constraints = [\n",
    "    lambda x: x[\"MGTOW\"] != 0 and x[\"MGTOW\"] + x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"]== 1,\n",
    "    lambda x: x[\"MRA\"] != 0 and x[\"MRA\"] + x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"Incel\"] != 0 and x[\"Incel\"] + x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"PUA\"] != 0 and x[\"PUA\"] + x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"MGTOW\"] + x[\"Incel\"] + x[\"MRA\"] + x[\"PUA\"] != 0 and x[\"MGTOW\"] + x[\"Incel\"] + x[\"MRA\"] \\\n",
    "              + x[\"PUA\"] + x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"Control\"] != 0 and x[\"Control\"] + x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"Intellectual Dark Web\"] + x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"Alt-lite\"] == 1,\n",
    "    lambda x: x[\"Intellectual Dark Web\"] == 1,\n",
    "]\n",
    "\n",
    "estimates = []\n",
    "p = (1,9999)\n",
    "\n",
    "for lamb, cname in zip(constraints, constraints_names):\n",
    "    already_tracked = set()\n",
    "\n",
    "    for start in list(range(4)):\n",
    "        non_radical = find_users_constraint(bin_users, bins_y_s[start], lamb)\n",
    "        non_radical = set(non_radical) - set(already_tracked)\n",
    "        already_tracked = already_tracked.union(non_radical)\n",
    "        non_radical = list(non_radical)\n",
    "\n",
    "        tmp = estimate_for_users(bin_users, bins_y_s[start], non_radical, \n",
    "                                 lambda xs: mean_confidence_interval([p[1] > x[\"Alt-right\"] *  \n",
    "                                                                      x[\"count\"] >= p[0] for x in xs]))\n",
    "\n",
    "        tmp[\"idxo\"] = start\n",
    "        tmp[\"idx\"] = bins_y_s[start]\n",
    "        tmp[\"start\"] = start\n",
    "        tmp[\"p\"] = p\n",
    "        tmp[\"numUsersStart\"] = len(non_radical)\n",
    "        tmp[\"numUsersTracked\"] = len(non_radical)\n",
    "        tmp[\"pUsersTracked\"] = 1\n",
    "        tmp[\"constraint\"] = cname\n",
    "        tmp[\"numUsersInfected\"] = 0\n",
    "        tmp[\"pUsersInfected\"] = 0\n",
    "\n",
    "        estimates.append(tmp)\n",
    "        count = 0\n",
    "        for bin_key in bins_y_s[start+1:]:\n",
    "            count += 1\n",
    "            tracked_users = find_users_other_bin(bin_users, bin_key, non_radical)\n",
    "\n",
    "            users_who_watched_ar = find_users_constraint(bin_users, bin_key, \n",
    "                      lambda x: p[1] > x[\"Alt-right\"] * x[\"count\"] >= p[0])\n",
    "\n",
    "            tmp = estimate_for_users(bin_users, bin_key, tracked_users,\n",
    "                                 lambda xs: mean_confidence_interval([p[1] > x[\"Alt-right\"] *  \n",
    "                                                                      x[\"count\"] >= p[0] for x in xs]))\n",
    "\n",
    "\n",
    "            tmp[\"idx\"] =  bin_key\n",
    "            tmp[\"idxo\"] = start + count\n",
    "            tmp[\"p\"] = p\n",
    "            tmp[\"start\"] = start\n",
    "            tmp[\"numUsersStart\"] = len(non_radical)\n",
    "            tmp[\"numUsersTracked\"] = len(tracked_users)\n",
    "            tmp[\"pUsersTracked\"] = len(tracked_users)/len(non_radical) if len(non_radical) != 0 else 0\n",
    "            tmp[\"numUsersInfected\"] = len(tracked_users) * tmp[\"mean\"]\n",
    "            tmp[\"pUsersInfected\"] =  tmp[\"numUsersInfected\"]/len(users_who_watched_ar)\n",
    "\n",
    "            tmp[\"constraint\"] = cname\n",
    "\n",
    "            estimates.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(estimates)\n",
    "\n",
    "with open(\"../helper_files/global_user_df.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}